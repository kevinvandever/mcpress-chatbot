#!/usr/bin/env python3
"""
Upload all PDFs to the Railway backend
This script uploads PDFs from your local backend/uploads directory 
to the Railway-deployed backend with full processing
"""

import os
import requests
import time
from pathlib import Path
import sys
import json

# Configuration
API_URL = "https://mcpress-chatbot-production-569b.up.railway.app"
PDF_DIRECTORY = "/Users/kevinvandever/kev-dev/pdf-chatbot/backend/uploads"
BATCH_SIZE = 1  # One file at a time for Railway
DELAY_BETWEEN_BATCHES = 30  # Shorter delay between individual files

def get_existing_documents():
    """Get list of already uploaded documents"""
    try:
        response = requests.get(f"{API_URL}/documents", timeout=30)
        if response.status_code == 200:
            data = response.json()
            # Handle different response formats
            if isinstance(data, dict):
                docs = data.get('documents', [])
            else:
                docs = data
            
            # Extract filenames from documents
            filenames = []
            for doc in docs:
                if isinstance(doc, dict):
                    filenames.append(doc.get('filename', ''))
                elif isinstance(doc, str):
                    filenames.append(doc)
            
            return [f for f in filenames if f]  # Remove empty strings
        else:
            print(f"Error getting documents: {response.status_code}")
            return []
    except Exception as e:
        print(f"Error getting documents: {e}")
        return []

def upload_single_pdf(pdf_path, existing_docs):
    """Upload a single PDF with full processing"""
    filename = pdf_path.name
    
    # Skip if already uploaded
    if filename in existing_docs:
        print(f"  ‚è≠Ô∏è  Skipping {filename} (already uploaded)")
        return True
    
    try:
        print(f"  üì§ Uploading {filename}...")
        
        # Step 1: Upload PDF file with longer timeout and retry logic
        max_retries = 2
        for attempt in range(max_retries):
            try:
                with open(pdf_path, 'rb') as f:
                    files = {'file': (filename, f, 'application/pdf')}
                    # Much longer timeout for large PDFs
                    response = requests.post(f"{API_URL}/upload", files=files, timeout=300)
                break  # Success, exit retry loop
            except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:
                if attempt < max_retries - 1:
                    print(f"  ‚ö†Ô∏è  Connection error on attempt {attempt + 1}, retrying in 10 seconds...")
                    time.sleep(10)
                    continue
                else:
                    print(f"  ‚ùå Max retries exceeded for {filename}: {e}")
                    return False
        
        if response.status_code == 200:
            result = response.json()
            print(f"  ‚úÖ {filename} uploaded and processed successfully")
            return True
        else:
            print(f"  ‚ùå Error uploading {filename}: {response.status_code} - {response.text}")
            return False
            
    except Exception as e:
        print(f"  ‚ùå Error uploading {filename}: {e}")
        return False

def main():
    """Main upload process"""
    print(f"üöÄ Starting PDF upload to Railway backend: {API_URL}")
    
    # Check if PDF directory exists
    pdf_dir = Path(PDF_DIRECTORY)
    if not pdf_dir.exists():
        print(f"‚ùå PDF directory not found: {PDF_DIRECTORY}")
        sys.exit(1)
    
    # Get PDF files
    pdf_files = list(pdf_dir.glob("*.pdf"))
    print(f"üìö Found {len(pdf_files)} PDF files")
    
    if not pdf_files:
        print("‚ùå No PDF files found!")
        sys.exit(1)
    
    # Get existing documents
    print("üîç Checking existing documents...")
    existing_docs = get_existing_documents()
    print(f"üìã Found {len(existing_docs)} existing documents")
    
    # Filter out already uploaded files
    remaining_files = [f for f in pdf_files if f.name not in existing_docs]
    print(f"üì§ {len(remaining_files)} files need to be uploaded")
    
    if not remaining_files:
        print("‚úÖ All files are already uploaded!")
        return
    
    # Process in batches
    successful_uploads = 0
    failed_uploads = 0
    
    for i in range(0, len(remaining_files), BATCH_SIZE):
        batch = remaining_files[i:i + BATCH_SIZE]
        batch_num = (i // BATCH_SIZE) + 1
        total_batches = (len(remaining_files) + BATCH_SIZE - 1) // BATCH_SIZE
        
        print(f"\n=== Batch {batch_num}/{total_batches} ===")
        
        for pdf_file in batch:
            success = upload_single_pdf(pdf_file, existing_docs)
            if success:
                successful_uploads += 1
                existing_docs.append(pdf_file.name)  # Add to existing to avoid re-upload
            else:
                failed_uploads += 1
        
        # Wait between batches (except for the last batch)
        if i + BATCH_SIZE < len(remaining_files):
            print(f"‚è±Ô∏è  Waiting {DELAY_BETWEEN_BATCHES} seconds before next batch...")
            time.sleep(DELAY_BETWEEN_BATCHES)
    
    # Final summary
    print(f"\nüéØ Upload Complete!")
    print(f"‚úÖ Successful uploads: {successful_uploads}")
    print(f"‚ùå Failed uploads: {failed_uploads}")
    print(f"üìä Total documents in system: {len(existing_docs)}")
    
    if failed_uploads > 0:
        print("\n‚ö†Ô∏è  Some uploads failed. You can run this script again to retry failed uploads.")

if __name__ == "__main__":
    main()